{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Reinforcement Learning-based RAG System Implementation\n",
        "\n",
        "This notebook implements a Retrieval Augmented Generation (RAG) system enhanced with Reinforcement Learning (RL) capabilities. The system combines the power of large language models with efficient document retrieval, optimized through reinforcement learning.\n",
        "\n",
        "## Key Components\n",
        "\n",
        "1. **RAG System**:\n",
        "   - Uses FAISS for efficient vector similarity search\n",
        "   - Implements document chunking and embedding\n",
        "   - Integrates with Groq's LLM for text generation\n",
        "\n",
        "2. **Reinforcement Learning**:\n",
        "   - Policy network for document ranking optimization\n",
        "   - Reward system based on answer relevance and diversity\n",
        "   - Learning through experience to improve retrieval quality\n",
        "\n",
        "3. **Core Technologies**:\n",
        "   - Groq LLM integration via langchain_groq\n",
        "   - HuggingFace embeddings for text encoding\n",
        "   - PyTorch for neural network implementation\n",
        "   - FAISS for vector storage and retrieval\n",
        "\n",
        "## Setup Requirements\n",
        "\n",
        "The following packages will be installed:\n",
        "- langchain_groq: For LLM integration\n",
        "- langchain-community: For document processing\n",
        "- faiss-cpu: For vector similarity search\n",
        "\n",
        "Note: This implementation requires a valid Groq API key stored in Google Colab secrets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Package Installation and Environment Setup\n",
        "\n",
        "This cell installs the required packages and sets up the Groq API key. We'll install:\n",
        "- `langchain_groq`: For interacting with Groq's LLM\n",
        "- `langchain-community`: For document processing utilities\n",
        "- `faiss-cpu`: For efficient vector similarity search\n",
        "\n",
        "The API key is securely stored in Google Colab's secrets management system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vU_O57m2UiWX"
      },
      "outputs": [],
      "source": [
        "!pip install langchain_groq langchain-community faiss-cpu\n",
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ[\"GROQ_API_KEY\"] = userdata.get('groq_api_key')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Core Components Implementation\n",
        "\n",
        "This section implements the fundamental components of our RL-RAG system:\n",
        "\n",
        "1. **Imports**: Required libraries for deep learning, natural language processing, and vector operations\n",
        "2. **PolicyNetwork Class**: Neural network architecture for learning document ranking\n",
        "   - Input: Combined query and document embeddings\n",
        "   - Architecture: 3-layer feed-forward network with ReLU activation\n",
        "   - Output: Scalar score for document relevance\n",
        "   - Initialization: Xavier uniform for weights, small positive bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.schema import HumanMessage, SystemMessage\n",
        "from langchain_groq import ChatGroq\n",
        "import os\n",
        "\n",
        "class PolicyNetwork(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=128):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, 1))\n",
        "\n",
        "        for layer in self.net:\n",
        "            if isinstance(layer, nn.Linear):\n",
        "                nn.init.xavier_uniform_(layer.weight)\n",
        "                nn.init.constant_(layer.bias, 0.1)\n",
        "\n",
        "    def forward(self, state):\n",
        "        return self.net(state)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## RL-RAG System Implementation\n",
        "\n",
        "The `RLRAGSystem` class integrates RAG with reinforcement learning:\n",
        "\n",
        "### Key Methods:\n",
        "- `load_documents`: Processes input text into manageable chunks\n",
        "- `initialize_embeddings`: Sets up sentence embeddings using HuggingFace\n",
        "- `initialize_retriever`: Configures FAISS vector store with MMR retrieval\n",
        "- `initialize_policy`: Creates the policy network and optimizer\n",
        "- `get_state`: Generates state representations for RL\n",
        "- `calculate_reward`: Computes rewards based on answer quality and diversity\n",
        "- `train_step`: Performs one iteration of policy optimization\n",
        "\n",
        "### Features:\n",
        "- MMR (Maximum Marginal Relevance) for diverse document selection\n",
        "- Hybrid reward system considering both relevance and diversity\n",
        "- Robust error handling for production environments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RLRAGSystem:\n",
        "    def __init__(self, data_path):\n",
        "        self.load_documents(data_path)\n",
        "        self.initialize_embeddings()\n",
        "        self.initialize_retriever()\n",
        "        self.initialize_policy()\n",
        "        self.llm = ChatGroq(temperature=0, model_name=\"llama3-70b-8192\")\n",
        "        self.min_documents = 1\n",
        "\n",
        "    def load_documents(self, path):\n",
        "        loader = TextLoader(path)\n",
        "        documents = loader.load()\n",
        "        splitter = CharacterTextSplitter(\n",
        "            chunk_size=300,\n",
        "            chunk_overlap=50,\n",
        "            separator=\"\\n\",\n",
        "            length_function=len\n",
        "        )\n",
        "        self.texts = splitter.split_documents(documents)\n",
        "        print(f\"Loaded {len(self.texts)} document chunks\")\n",
        "\n",
        "    def initialize_embeddings(self):\n",
        "        self.embeddings = HuggingFaceEmbeddings(\n",
        "            model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "        )\n",
        "\n",
        "    def initialize_retriever(self):\n",
        "        self.vector_store = FAISS.from_documents(self.texts, self.embeddings)\n",
        "        self.retriever = self.vector_store.as_retriever(\n",
        "            search_type=\"mmr\",\n",
        "            search_kwargs={\"k\": 3, \"fetch_k\": 10}\n",
        "        )\n",
        "\n",
        "    def initialize_policy(self):\n",
        "        state_dim = 384 * 2\n",
        "        self.policy = PolicyNetwork(state_dim)\n",
        "        self.optimizer = optim.Adam(self.policy.parameters(), lr=1e-4)\n",
        "\n",
        "    def get_state(self, query, document):\n",
        "        try:\n",
        "            query_embed = self.embeddings.embed_query(query)\n",
        "            doc_embed = self.embeddings.embed_query(document.page_content)\n",
        "            return torch.FloatTensor(query_embed + doc_embed)\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "    def calculate_reward(self, query, documents, answer):\n",
        "        try:\n",
        "            answer_lower = answer.lower()\n",
        "            query_words = set(query.lower().split())\n",
        "            answer_words = set(answer_lower.split())\n",
        "            match_score = len(query_words & answer_words) / len(query_words)\n",
        "            unique_docs = len({d.page_content[:50] for d in documents})\n",
        "            diversity_score = unique_docs / len(documents)\n",
        "            return 0.7 * match_score + 0.3 * diversity_score\n",
        "        except:\n",
        "            return 0.0\n",
        "\n",
        "    def train_step(self, query, true_answer):\n",
        "        try:\n",
        "            documents = self.retriever.get_relevant_documents(query)\n",
        "            if len(documents) < self.min_documents:\n",
        "                return 0.0, 0.0\n",
        "\n",
        "            if len(documents) == 1:\n",
        "                return 0.0, 0.0  # Skip single-document ranking\n",
        "\n",
        "            states = [self.get_state(query, doc) for doc in documents]\n",
        "            valid_states = [s for s in states if s is not None]\n",
        "\n",
        "            if len(valid_states) < 2:\n",
        "                return 0.0, 0.0\n",
        "\n",
        "            # Fixed dimension handling\n",
        "            scores = torch.stack([self.policy(state) for state in valid_states]).squeeze(-1)\n",
        "            probs = torch.softmax(scores, dim=0)\n",
        "\n",
        "            # Ensure valid sampling\n",
        "            n_samples = min(len(valid_states), probs.size(-1))\n",
        "            sorted_indices = torch.multinomial(probs, n_samples, replacement=False)\n",
        "\n",
        "            ranked_docs = [documents[i] for i in sorted_indices]\n",
        "            context = \"\\n\".join([d.page_content for d in ranked_docs[:3]])\n",
        "            answer = self.llm([\n",
        "                SystemMessage(content=f\"Answer based on:\\n{context}\"),\n",
        "                HumanMessage(content=query)\n",
        "            ]).content\n",
        "\n",
        "            reward = self.calculate_reward(query, ranked_docs, answer)\n",
        "            log_probs = torch.log(probs.gather(0, sorted_indices))\n",
        "            loss = -torch.mean(log_probs) * reward\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            return loss.item(), reward\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Training error: {str(e)}\")\n",
        "            return 0.0, 0.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Loop Implementation\n",
        "\n",
        "The `train_rag` function orchestrates the training process:\n",
        "\n",
        "- Iterates through multiple epochs\n",
        "- Processes query-answer pairs\n",
        "- Tracks and reports training metrics:\n",
        "  - Loss: Indicates policy improvement\n",
        "  - Reward: Measures retrieval quality\n",
        "\n",
        "The training loop includes validation checks and detailed logging for monitoring the learning progress."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_rag(rl_rag, queries, answers, epochs=50):\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0.0\n",
        "        total_reward = 0.0\n",
        "        valid_steps = 0\n",
        "\n",
        "        for query, answer in zip(queries, answers):\n",
        "            loss, reward = rl_rag.train_step(query, answer)\n",
        "            if loss != 0 or reward != 0:\n",
        "                total_loss += loss\n",
        "                total_reward += reward\n",
        "                valid_steps += 1\n",
        "\n",
        "        if valid_steps > 0:\n",
        "            avg_loss = total_loss / valid_steps\n",
        "            avg_reward = total_reward / valid_steps\n",
        "            print(f\"\\nEpoch {epoch+1}: Loss: {avg_loss:.4f}, Reward: {avg_reward:.4f}\")\n",
        "        else:\n",
        "            print(f\"\\nEpoch {epoch+1}: No valid training steps\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sample Data Generation\n",
        "\n",
        "The `create_sample_data` function generates a diverse dataset covering AI topics:\n",
        "\n",
        "- Creates structured paragraphs on various AI concepts\n",
        "- Topics include: AI basics, machine learning, deep learning, neural networks\n",
        "- Saves data with appropriate formatting for retrieval\n",
        "\n",
        "This synthetic dataset helps demonstrate and validate the RL-RAG system's capabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def create_sample_data():\n",
        "    paragraphs = [\n",
        "        \"Artificial Intelligence (AI) is the simulation of human intelligence in machines. AI systems are designed to perform tasks like visual perception, speech recognition, and decision-making. Modern AI techniques include machine learning, deep learning, and neural networks.\",\n",
        "        \"Machine learning is a subset of AI that enables systems to learn from data without explicit programming. There are three main types: supervised learning (labeled data), unsupervised learning (unlabeled data), and reinforcement learning (reward-based learning).\",\n",
        "        \"Deep learning uses artificial neural networks with multiple layers to model complex patterns. Common architectures include CNNs for image processing and RNNs for sequence data. Transformers have recently become popular for NLP tasks.\",\n",
        "        \"Neural networks are computing systems inspired by biological neurons. They consist of interconnected nodes (neurons) organized in layers. Training involves forward propagation and backpropagation to adjust weights.\",\n",
        "        \"Reinforcement learning is a type of machine learning where agents learn by interacting with an environment. Key components include states, actions, rewards, and policies. Popular algorithms are Q-learning and policy gradient methods.\",\n",
        "        \"Natural Language Processing (NLP) enables computers to understand human language. Techniques include tokenization, word embeddings (Word2Vec, GloVe), and transformer models (BERT, GPT).\",\n",
        "        \"Computer Vision focuses on enabling machines to interpret visual data. Common tasks include image classification, object detection, and image segmentation. Popular frameworks are OpenCV and PyTorch Vision.\",\n",
        "        \"The Turing Test evaluates a machine's ability to exhibit intelligent behavior indistinguishable from humans. Alan Turing proposed this test in 1950 as a measure of true AI.\",\n",
        "        \"Ethics in AI involves addressing bias, privacy concerns, and transparency. Responsible AI development requires considering societal impacts and potential misuse of technology.\"\n",
        "    ]\n",
        "\n",
        "    with open('sample_data.txt', 'w') as f:\n",
        "        f.write(\"\\n\\n\".join(paragraphs))  # Use double newlines between paragraphs\n",
        "    print(\"Sample data created with 9 paragraphs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Main Execution Block\n",
        "\n",
        "The main execution section demonstrates the complete workflow:\n",
        "\n",
        "1. **Data Preparation**:\n",
        "   - Creates sample AI-focused dataset\n",
        "   - Initializes the RL-RAG system\n",
        "\n",
        "2. **Training Setup**:\n",
        "   - Defines diverse query-answer pairs\n",
        "   - Covers various AI topics for comprehensive learning\n",
        "\n",
        "3. **System Training**:\n",
        "   - Runs training for 10 epochs\n",
        "   - Demonstrates retrieval capabilities with a test query\n",
        "\n",
        "The output shows progressive improvement in retrieval quality and answer relevance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mK_ssNyOUaFF",
        "outputId": "b44955de-3ab7-403f-fa74-248ea11e839f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample data created with 9 paragraphs\n",
            "Loaded 9 document chunks\n",
            "\n",
            "Epoch 1: Loss: 0.7464, Reward: 0.6792\n",
            "\n",
            "Epoch 2: Loss: 0.7462, Reward: 0.6792\n",
            "\n",
            "Epoch 3: Loss: 0.7462, Reward: 0.6792\n",
            "\n",
            "Epoch 4: Loss: 0.7718, Reward: 0.7025\n",
            "\n",
            "Epoch 5: Loss: 0.7461, Reward: 0.6792\n",
            "\n",
            "Epoch 6: Loss: 0.7615, Reward: 0.6932\n",
            "\n",
            "Epoch 7: Loss: 0.7872, Reward: 0.7165\n",
            "\n",
            "Epoch 8: Loss: 0.7718, Reward: 0.7025\n",
            "\n",
            "Epoch 9: Loss: 0.7615, Reward: 0.6932\n",
            "\n",
            "Epoch 10: Loss: 0.7461, Reward: 0.6792\n",
            "\n",
            "Test retrieval results:\n",
            "[Doc 1] Deep learning uses artificial neural networks with multiple layers to model comp...\n",
            "[Doc 2] Reinforcement learning is a type of machine learning where agents learn by inter...\n",
            "[Doc 3] Ethics in AI involves addressing bias, privacy concerns, and transparency. Respo...\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Create properly formatted sample data\n",
        "    create_sample_data()\n",
        "\n",
        "    # Initialize system\n",
        "    rag_system = RLRAGSystem(\"sample_data.txt\")\n",
        "\n",
        "    # Training data\n",
        "    queries = [\n",
        "        \"What is machine learning?\",\n",
        "        \"Explain neural networks\",\n",
        "        \"How does reinforcement learning work?\",\n",
        "        \"What are the main AI techniques?\",\n",
        "        \"Describe deep learning architectures\",\n",
        "        \"What's the difference between AI and machine learning?\",\n",
        "        \"How do transformers work in NLP?\",\n",
        "        \"What is the Turing Test?\",\n",
        "        \"List computer vision applications\",\n",
        "        \"Why are ethics important in AI?\"\n",
        "    ]\n",
        "\n",
        "    answers = [\n",
        "        \"Machine learning is a subset of AI...\",\n",
        "        \"Neural networks are computing systems...\",\n",
        "        \"Reinforcement learning involves agents...\",\n",
        "        \"Main AI techniques include machine learning...\",\n",
        "        \"Deep learning architectures include CNNs...\",\n",
        "        \"AI is the broader concept...\",\n",
        "        \"Transformers process words using self-attention...\",\n",
        "        \"The Turing Test evaluates machine intelligence...\",\n",
        "        \"Applications include image classification...\",\n",
        "        \"AI ethics addresses bias and privacy...\"\n",
        "    ]\n",
        "\n",
        "    # Train the system\n",
        "    train_rag(rag_system, queries, answers, epochs=10)\n",
        "\n",
        "    # Test retrieval\n",
        "    test_query = \"What is deep learning?\"\n",
        "    documents = rag_system.retriever.get_relevant_documents(test_query)\n",
        "    print(\"\\nTest retrieval results:\")\n",
        "    for i, doc in enumerate(documents):\n",
        "        print(f\"[Doc {i+1}] {doc.page_content[:80]}...\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "genai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
