{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_groq langchain-community faiss-cpu"
      ],
      "metadata": {
        "id": "2MvaeWGOJRci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ[\"GROQ_API_KEY\"] = userdata.get('groq_api_key')\n"
      ],
      "metadata": {
        "id": "vU_O57m2UiWX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.schema import HumanMessage, SystemMessage\n",
        "from langchain_groq import ChatGroq\n",
        "import os\n",
        "\n",
        "class PolicyNetwork(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=128):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, 1))\n",
        "\n",
        "        for layer in self.net:\n",
        "            if isinstance(layer, nn.Linear):\n",
        "                nn.init.xavier_uniform_(layer.weight)\n",
        "                nn.init.constant_(layer.bias, 0.1)\n",
        "\n",
        "    def forward(self, state):\n",
        "        return self.net(state)\n",
        "\n",
        "class RLRAGSystem:\n",
        "    def __init__(self, data_path):\n",
        "        self.load_documents(data_path)\n",
        "        self.initialize_embeddings()\n",
        "        self.initialize_retriever()\n",
        "        self.initialize_policy()\n",
        "        self.llm = ChatGroq(temperature=0, model_name=\"llama3-70b-8192\")\n",
        "        self.min_documents = 1\n",
        "\n",
        "    def load_documents(self, path):\n",
        "        loader = TextLoader(path)\n",
        "        documents = loader.load()\n",
        "        splitter = CharacterTextSplitter(\n",
        "            chunk_size=300,\n",
        "            chunk_overlap=50,\n",
        "            separator=\"\\n\",\n",
        "            length_function=len\n",
        "        )\n",
        "        self.texts = splitter.split_documents(documents)\n",
        "        print(f\"Loaded {len(self.texts)} document chunks\")\n",
        "\n",
        "    def initialize_embeddings(self):\n",
        "        self.embeddings = HuggingFaceEmbeddings(\n",
        "            model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "        )\n",
        "\n",
        "    def initialize_retriever(self):\n",
        "        self.vector_store = FAISS.from_documents(self.texts, self.embeddings)\n",
        "        self.retriever = self.vector_store.as_retriever(\n",
        "            search_type=\"mmr\",\n",
        "            search_kwargs={\"k\": 3, \"fetch_k\": 10}\n",
        "        )\n",
        "\n",
        "    def initialize_policy(self):\n",
        "        state_dim = 384 * 2\n",
        "        self.policy = PolicyNetwork(state_dim)\n",
        "        self.optimizer = optim.Adam(self.policy.parameters(), lr=1e-4)\n",
        "\n",
        "    def get_state(self, query, document):\n",
        "        try:\n",
        "            query_embed = self.embeddings.embed_query(query)\n",
        "            doc_embed = self.embeddings.embed_query(document.page_content)\n",
        "            return torch.FloatTensor(query_embed + doc_embed)\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "    def calculate_reward(self, query, documents, answer):\n",
        "        try:\n",
        "            answer_lower = answer.lower()\n",
        "            query_words = set(query.lower().split())\n",
        "            answer_words = set(answer_lower.split())\n",
        "            match_score = len(query_words & answer_words) / len(query_words)\n",
        "            unique_docs = len({d.page_content[:50] for d in documents})\n",
        "            diversity_score = unique_docs / len(documents)\n",
        "            return 0.7 * match_score + 0.3 * diversity_score\n",
        "        except:\n",
        "            return 0.0\n",
        "\n",
        "    def train_step(self, query, true_answer):\n",
        "        try:\n",
        "            documents = self.retriever.get_relevant_documents(query)\n",
        "            if len(documents) < self.min_documents:\n",
        "                return 0.0, 0.0\n",
        "\n",
        "            if len(documents) == 1:\n",
        "                return 0.0, 0.0  # Skip single-document ranking\n",
        "\n",
        "            states = [self.get_state(query, doc) for doc in documents]\n",
        "            valid_states = [s for s in states if s is not None]\n",
        "\n",
        "            if len(valid_states) < 2:\n",
        "                return 0.0, 0.0\n",
        "\n",
        "            # Fixed dimension handling\n",
        "            scores = torch.stack([self.policy(state) for state in valid_states]).squeeze(-1)\n",
        "            probs = torch.softmax(scores, dim=0)\n",
        "\n",
        "            # Ensure valid sampling\n",
        "            n_samples = min(len(valid_states), probs.size(-1))\n",
        "            sorted_indices = torch.multinomial(probs, n_samples, replacement=False)\n",
        "\n",
        "            ranked_docs = [documents[i] for i in sorted_indices]\n",
        "            context = \"\\n\".join([d.page_content for d in ranked_docs[:3]])\n",
        "            answer = self.llm([\n",
        "                SystemMessage(content=f\"Answer based on:\\n{context}\"),\n",
        "                HumanMessage(content=query)\n",
        "            ]).content\n",
        "\n",
        "            reward = self.calculate_reward(query, ranked_docs, answer)\n",
        "            log_probs = torch.log(probs.gather(0, sorted_indices))\n",
        "            loss = -torch.mean(log_probs) * reward\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            return loss.item(), reward\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Training error: {str(e)}\")\n",
        "            return 0.0, 0.0\n",
        "\n",
        "# Rest of the code remains the same for training loop and data creation\n",
        "\n",
        "def train_rag(rl_rag, queries, answers, epochs=50):\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0.0\n",
        "        total_reward = 0.0\n",
        "        valid_steps = 0\n",
        "\n",
        "        for query, answer in zip(queries, answers):\n",
        "            loss, reward = rl_rag.train_step(query, answer)\n",
        "            if loss != 0 or reward != 0:\n",
        "                total_loss += loss\n",
        "                total_reward += reward\n",
        "                valid_steps += 1\n",
        "\n",
        "        if valid_steps > 0:\n",
        "            avg_loss = total_loss / valid_steps\n",
        "            avg_reward = total_reward / valid_steps\n",
        "            print(f\"\\nEpoch {epoch+1}: Loss: {avg_loss:.4f}, Reward: {avg_reward:.4f}\")\n",
        "        else:\n",
        "            print(f\"\\nEpoch {epoch+1}: No valid training steps\")\n",
        "\n",
        "# Create proper sample data\n",
        "def create_sample_data():\n",
        "    paragraphs = [\n",
        "        \"Artificial Intelligence (AI) is the simulation of human intelligence in machines. AI systems are designed to perform tasks like visual perception, speech recognition, and decision-making. Modern AI techniques include machine learning, deep learning, and neural networks.\",\n",
        "        \"Machine learning is a subset of AI that enables systems to learn from data without explicit programming. There are three main types: supervised learning (labeled data), unsupervised learning (unlabeled data), and reinforcement learning (reward-based learning).\",\n",
        "        \"Deep learning uses artificial neural networks with multiple layers to model complex patterns. Common architectures include CNNs for image processing and RNNs for sequence data. Transformers have recently become popular for NLP tasks.\",\n",
        "        \"Neural networks are computing systems inspired by biological neurons. They consist of interconnected nodes (neurons) organized in layers. Training involves forward propagation and backpropagation to adjust weights.\",\n",
        "        \"Reinforcement learning is a type of machine learning where agents learn by interacting with an environment. Key components include states, actions, rewards, and policies. Popular algorithms are Q-learning and policy gradient methods.\",\n",
        "        \"Natural Language Processing (NLP) enables computers to understand human language. Techniques include tokenization, word embeddings (Word2Vec, GloVe), and transformer models (BERT, GPT).\",\n",
        "        \"Computer Vision focuses on enabling machines to interpret visual data. Common tasks include image classification, object detection, and image segmentation. Popular frameworks are OpenCV and PyTorch Vision.\",\n",
        "        \"The Turing Test evaluates a machine's ability to exhibit intelligent behavior indistinguishable from humans. Alan Turing proposed this test in 1950 as a measure of true AI.\",\n",
        "        \"Ethics in AI involves addressing bias, privacy concerns, and transparency. Responsible AI development requires considering societal impacts and potential misuse of technology.\"\n",
        "    ]\n",
        "\n",
        "    with open('sample_data.txt', 'w') as f:\n",
        "        f.write(\"\\n\\n\".join(paragraphs))  # Use double newlines between paragraphs\n",
        "    print(\"Sample data created with 9 paragraphs\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Create properly formatted sample data\n",
        "    create_sample_data()\n",
        "\n",
        "    # Initialize system\n",
        "    rag_system = RLRAGSystem(\"sample_data.txt\")\n",
        "\n",
        "    # Training data\n",
        "    queries = [\n",
        "        \"What is machine learning?\",\n",
        "        \"Explain neural networks\",\n",
        "        \"How does reinforcement learning work?\",\n",
        "        \"What are the main AI techniques?\",\n",
        "        \"Describe deep learning architectures\",\n",
        "        \"What's the difference between AI and machine learning?\",\n",
        "        \"How do transformers work in NLP?\",\n",
        "        \"What is the Turing Test?\",\n",
        "        \"List computer vision applications\",\n",
        "        \"Why are ethics important in AI?\"\n",
        "    ]\n",
        "\n",
        "    answers = [\n",
        "        \"Machine learning is a subset of AI...\",\n",
        "        \"Neural networks are computing systems...\",\n",
        "        \"Reinforcement learning involves agents...\",\n",
        "        \"Main AI techniques include machine learning...\",\n",
        "        \"Deep learning architectures include CNNs...\",\n",
        "        \"AI is the broader concept...\",\n",
        "        \"Transformers process words using self-attention...\",\n",
        "        \"The Turing Test evaluates machine intelligence...\",\n",
        "        \"Applications include image classification...\",\n",
        "        \"AI ethics addresses bias and privacy...\"\n",
        "    ]\n",
        "\n",
        "    # Train the system\n",
        "    train_rag(rag_system, queries, answers, epochs=10)\n",
        "\n",
        "    # Test retrieval\n",
        "    test_query = \"What is deep learning?\"\n",
        "    documents = rag_system.retriever.get_relevant_documents(test_query)\n",
        "    print(\"\\nTest retrieval results:\")\n",
        "    for i, doc in enumerate(documents):\n",
        "        print(f\"[Doc {i+1}] {doc.page_content[:80]}...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mK_ssNyOUaFF",
        "outputId": "b44955de-3ab7-403f-fa74-248ea11e839f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample data created with 9 paragraphs\n",
            "Loaded 9 document chunks\n",
            "\n",
            "Epoch 1: Loss: 0.7464, Reward: 0.6792\n",
            "\n",
            "Epoch 2: Loss: 0.7462, Reward: 0.6792\n",
            "\n",
            "Epoch 3: Loss: 0.7462, Reward: 0.6792\n",
            "\n",
            "Epoch 4: Loss: 0.7718, Reward: 0.7025\n",
            "\n",
            "Epoch 5: Loss: 0.7461, Reward: 0.6792\n",
            "\n",
            "Epoch 6: Loss: 0.7615, Reward: 0.6932\n",
            "\n",
            "Epoch 7: Loss: 0.7872, Reward: 0.7165\n",
            "\n",
            "Epoch 8: Loss: 0.7718, Reward: 0.7025\n",
            "\n",
            "Epoch 9: Loss: 0.7615, Reward: 0.6932\n",
            "\n",
            "Epoch 10: Loss: 0.7461, Reward: 0.6792\n",
            "\n",
            "Test retrieval results:\n",
            "[Doc 1] Deep learning uses artificial neural networks with multiple layers to model comp...\n",
            "[Doc 2] Reinforcement learning is a type of machine learning where agents learn by inter...\n",
            "[Doc 3] Ethics in AI involves addressing bias, privacy concerns, and transparency. Respo...\n"
          ]
        }
      ]
    }
  ]
}